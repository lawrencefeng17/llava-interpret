{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import requests\n",
    "import torch\n",
    "import transformers\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"llava-hf/llava-1.5-7b-hf\"\n",
    "\n",
    "model = transformers.LlavaForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',\n",
    "    quantization_config=transformers.BitsAndBytesConfig(load_in_8bit=True),\n",
    ")\n",
    "processor = transformers.AutoProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "\n",
    "import psutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load tensors\n",
    "def load_tensors(folder):\n",
    "    data = []\n",
    "    for file in tqdm(os.listdir(folder)):\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        if memory_usage > 90:\n",
    "            print(\"Memory usage exceeded 90%. Breaking the loop.\")\n",
    "            break\n",
    "        if file.endswith(\".pt\"):  # Assuming tensors are saved as .pt files\n",
    "            label = file.split('[')[1].split(']')[0]\n",
    "            try:\n",
    "                tensor = torch.load(os.path.join(folder, file), map_location='cpu')\n",
    "            except:\n",
    "                continue\n",
    "            data.append((label, tensor))\n",
    "    return data\n",
    "\n",
    "def reduce_dimension(data, method=\"PCA\", n_components=2):\n",
    "    flattened_data = []\n",
    "    for label, tensor in data:\n",
    "        mean_activation = tensor.mean(dim=0)  # Mean pooling over tokens\n",
    "        flattened_data.append(mean_activation.detach().numpy())\n",
    "        labels.append(label)\n",
    "\n",
    "    flattened_data = np.array(flattened_data)\n",
    "    if method == \"PCA\":\n",
    "        reducer = PCA(n_components=n_components)\n",
    "    elif method == \"TSNE\":\n",
    "        reducer = TSNE(n_components=n_components)\n",
    "    elif method == \"UMAP\":\n",
    "        reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported reduction method\")\n",
    "    reduced_data = reducer.fit_transform(flattened_data)\n",
    "    return reduced_data, labels\n",
    "    \n",
    "# Plot\n",
    "def plot_2d(data, labels, title=\"Hidden States Visualization\"):\n",
    "    unique_labels = list(set(labels))\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(unique_labels))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        indices = [j for j, lbl in enumerate(labels) if lbl == label]\n",
    "        plt.scatter(data[indices, 0], data[indices, 1], label=label, color=colors(i))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/raid/lawrence/hidden_states/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tensors = []\n",
    "for file in tqdm(os.listdir(folder_path)):\n",
    "    data = np.load(folder_path + file)\n",
    "    tensor = torch.from_numpy(data['hidden_states'])\n",
    "    tensors.append(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def filter(data):\n",
    "    print(len(data))\n",
    "    label_to_values = defaultdict(list)\n",
    "    for label, value in data:\n",
    "        label_to_values[label].append(value)\n",
    "\n",
    "    # print([len(value) for key, value in label_to_values.items()])\n",
    "    \n",
    "    # Step 2: Filter labels with more than one value\n",
    "    filtered_labels = {label for label, values in label_to_values.items() if len(values) > 10}\n",
    "    \n",
    "    # Step 3: Filter the original list\n",
    "    filtered_data = [(label, value) for label, value in data if label in filtered_labels]\n",
    "    print(len(filtered_data))\n",
    "    return filtered_data\n",
    "\n",
    "filtered_data = filter(data)\n",
    "reduced_data, labels = reduce_dimension(filtered_data, method=\"UMAP\")  # or method=\"TSNE\"\n",
    "plot_2d(reduced_data, labels)\n",
    "\n",
    "chosen = [str(i) for i in range(55,65)]\n",
    "filtered_special = [(label, value) for label, value in data if label in chosen]\n",
    "reduced_data, labels = reduce_dimension(filtered_special, method=\"PCA\")  # or method=\"TSNE\"\n",
    "plot_2d(reduced_data, labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
